{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pandas import concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "instructions for how to obtain final compiled cytogenetics report and karyotype for the input of all csv files exported from powerpath via crystalreport from Michelle.\n",
    "\n",
    "first: there are 2 seperate scripts, one for karyotype, the other for cyto report. I may eventually combine them since they use similar scripting.\n",
    "This script requires a bit of manual work as well, and may be updated to remove that in the future.\n",
    "\n",
    "First compile all of the csv files into the path folder. \n",
    "\n",
    "run the two cytogenetic report scripts.\n",
    "\n",
    "next Run the first karyotype script. Next, manually delete the columns with blanks or column names in them, and add in column headers (see the note above the script).\n",
    "\n",
    "Run the second karyotype script\n",
    "\n",
    "Now, these two must be manually vlooked up in excel inorder to obtain a report with 1 row for each accession # that contains the full cyto report and karyotype\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cytogenetic report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code to take all csv files in my \"cytogenetiics\" folder and merge them into 1 large csv files for all 2013-2015 cytogenetics reports.\n",
    "\n",
    "\n",
    "\n",
    "path = r'C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\cytogeneticcsvs\\rawfiles'\n",
    "allFiles = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "df = pd.concat(( pd.read_csv(f, names=['Accession', 'MRN','Patient Name', 'DOB', 'Test Name', 'Collect Date', 'Recieved date', 'report Header', 'Results']) for f in allFiles))\n",
    "\n",
    "\n",
    "#df = pd.concat((pd.read_csv(f) for f in allFiles))\n",
    "#df = df.drop_duplicates(subset=['b'],keep= 'first')\n",
    "df.to_csv('C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\cytogeneticcsvs\\\\allcytonew3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 tier code\n",
    "#first tier: makes a list of all unique accession numbers as newlist, makes a new dictionary, and reads the merged csv from above.\n",
    "\n",
    "newlist = []\n",
    "df = pd.read_csv('C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\cytogeneticcsvs\\\\allcytonew3.csv')\n",
    "mydict= {}\n",
    "for element in df['Accession']:\n",
    "    newlist.append(element)\n",
    "newlist= list(set(newlist))\n",
    "#print df, works\n",
    "#print newlist\n",
    "\n",
    "#######################################\n",
    "#second tier: for every accession number, it returns, and merges all values in the 'result' row for that accession number so that all parts of the cyto\n",
    "#report are merged into 1 cell. it then saves a key:value pair for the accession # (key) and the merged report (value) in {mydict}\n",
    "\n",
    "for element in newlist:  #aka element = loop over every accession #\n",
    "    dfcyto1 = df.loc[df['Accession'] == element, 'Results']   #dfhbm1 is dataframe for column results for the rows that are in column b are== to element\n",
    "    dfcyto1['merged'] =  dfcyto1.str.cat(sep=', ')\n",
    "    mydict[element] = dfcyto1['merged']\n",
    "\n",
    "######################################\n",
    "#third tier: df2= dataframe assembled from the tuples of each key:value pair in {mydict}, so there will be 1 row for each accesion number, and the \n",
    "#associated cytogenetics report for that accession #. \n",
    "#df3 merges the origional dataframe (with each row being a component of 1 cyto report), then removes the duplicates so that what remains is\n",
    "#1 row per accession # with all of the origional demographic information, as well as a complete cytogenetics report. \n",
    "#there is likely a much more elegant way to accomplish this goal, but it works and was the best i could do\n",
    "#with my novice skillset and the amount of time.\n",
    "\n",
    "df2 = pd.DataFrame(mydict.items(), columns=['Accession', \"report\"])     \n",
    "df3 = pd.merge(df, df2, on=\"Accession\")      \n",
    "df3 = df3.drop_duplicates(subset=['report'],keep= 'first')\n",
    "df3.to_csv('C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\cytogeneticcsvs\\\\cytoreports_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For Karyotype:\n",
    "\n",
    "note: after running part one, you will need to go in and delete the columns with row names, and assign the following column headers:\n",
    "Accessopn #\tMRN\tPatient Name\tDOB\tTest Name\tCollect Date\tRec Date\tReport Header\tResults\tkaryotype\n",
    "\n",
    "\n",
    "A code could easily be written to accomplish this, but I ran out of time and the indexing was being wonky in the few minutes I tried. \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#karyotype part 1.\n",
    "\n",
    "\n",
    "path = r'C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\cytogeneticcsvs\\rawfiles\\karyotype raw files'\n",
    "allFiles = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "df = pd.concat(( pd.read_csv(f, names=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x']) for f in allFiles))\n",
    "\n",
    "df = df[df.u ==\"IMPRESSIONS AND RECOMMENDATIONS:\"]\n",
    "        \n",
    "df = df[df.x != \"See below\"]\n",
    "\n",
    "#df = df.drop_duplicates(subset=['b'],keep= 'first')\n",
    "df.to_csv('C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\cytogeneticcsvs\\\\karyotypecompiled03d.csv', index=False)\n",
    "print\"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 tier code\n",
    "#first tier: makes a list of all unique accession numbers as newlist, makes a new dictionary, and reads the merged csv from above.\n",
    "\n",
    "unique_Accession = []\n",
    "df = pd.read_csv('C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\cytogeneticcsvs\\\\karyotypecompiled03d.csv')\n",
    "mydict= {}\n",
    "for element in df['Accession']:\n",
    "    unique_Accession.append(element)\n",
    "unique_Accession= list(set(unique_Accession))  #list of unique accession numbers\n",
    "\n",
    "#code to remove duplicate entries for karyotype subsets. \n",
    "df['removedup']= df['Accession']+df['Karyotype']\n",
    "df = df.drop_duplicates(subset=['removedup'],keep= 'first')\n",
    "\n",
    "\n",
    "for element in unique_Accession:  #aka element = loop over every accession #\n",
    "    dfcyto1 = df.loc[df['Accession'] == element, 'Karyotype']   #dfcyto1 is dataframe for column results for the rows that are in column b are== to element\n",
    "    dfcyto1['merged'] =  dfcyto1.str.cat(sep= \"\"\"\n",
    "    \"\"\")\n",
    "    mydict[element] = dfcyto1['merged']\n",
    "    \n",
    "\n",
    "df2 = pd.DataFrame(mydict.items(), columns=['Accession', \"Karyotype\"])\n",
    "df3 = pd.merge(df, df2, on='Accession')      \n",
    "df3 = df3.drop_duplicates(subset=['Accession'],keep= 'first')\n",
    "df3.to_csv(r'C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\cytogeneticcsvs\\\\testforkaryotype03output5test.csv', index=False)\n",
    "print\"done\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
