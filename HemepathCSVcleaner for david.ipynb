{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pandas import concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step 1, read file, parse out the columns, filter by accession no != NaN \n",
    "\n",
    "df = pd.read_csv('Hemepath2016(1).csv')             \n",
    "df.columns = ['a', \"b\",\"c\",\"d\",'e','f','g','h','i','j','k','l']\n",
    "df = df[df.a == 'Accession No']\n",
    "df = df.drop(df.columns[[0]], axis=1)\n",
    "df.to_csv('Hemepath2016(1).csv', error_bad_lines=False)\n",
    "print df''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step 2: removing duplicates.   remove all duplicate rows that will bog down the concatination.\n",
    "\n",
    "df = pd.read_csv('C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\hemepathcsvs\\HemePath2016(1).csv')\n",
    "df = df.drop_duplicates(subset=['l'],keep= 'first')\n",
    "df.to_csv('C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\hemepathcsvs\\HemePath2016(1).csv', index=False)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step 3: making a concensus report via concatination and removing all duplicate columns.\n",
    "\n",
    "newlist = []\n",
    "df = pd.read_csv('C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\hemepathcsvs\\HemePath2016(1).csv')\n",
    "mydict= {}\n",
    "for element in df['b']:\n",
    "    newlist.append(element)\n",
    "newlist= list(set(newlist))\n",
    "\n",
    "for element in newlist:\n",
    "    dfhbm1 = df.loc[df['b'] == element, 'l']  #dfhbm1 is dataframe of column l where rows in column b are== to element\n",
    "    dfhbm1['m'] =  dfhbm1.str.cat(sep=', ')\n",
    "    mydict[element] = dfhbm1['m']\n",
    "df2 = pd.DataFrame(mydict.items(), columns=['b', \"report\"])        \n",
    "df3 = pd.merge(df, df2, on=\"b\")      \n",
    "\n",
    "df3 = df3.drop_duplicates(subset=['report'],keep= 'first')\n",
    "print df3\n",
    "df3.to_csv('C:\\Users\\eickelbe\\Desktop\\google-python-exercises\\hemepathcsvs\\HemePath2016(1)v2.csv', index=False)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step 4:take all csv files in my \"finalfiles\" folder and merge them into 1 large csv files for all 1999-2015 hemepath reports.\n",
    "\n",
    "\n",
    "path = r'C:\\Users\\eickelbe\\Favorites\\Desktop\\google-python-exercises\\hemepathcsvs\\finalfiles'\n",
    "allFiles = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "df = pd.concat((pd.read_csv(f) for f in allFiles))\n",
    "df = df.drop_duplicates(subset=['b'],keep= 'first')\n",
    "df.to_csv('C:\\Users\\eickelbe\\Favorites\\Desktop\\google-python-exercises\\hemepathcsvs\\HemePath1999through2015.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the above steps all executed at the same time. If i remember correctly, this is what i ultimately used (so i didn't need to do the 4 steps above for every file)\n",
    "\n",
    "#consensus reports and all duplicate removal for all 15 files. (iteration version for multiple files)\n",
    "\n",
    "\n",
    "#all csv files were named \"HemePathxxxx, where xxxx is the year\" this just let me loop over all of them. \n",
    "for element in range (1,17):\n",
    "    year = str(1999 + element)\n",
    "    csvfile = (\"HemePath\" + year + \".csv\")\n",
    "    df = pd.read_csv(csvfile)\n",
    "    \n",
    "    #####################\n",
    "    \n",
    "    newlist = []\n",
    "    mydict= {}\n",
    "    for element in df['b']:\n",
    "        newlist.append(element)\n",
    "    newlist= list(set(newlist))\n",
    "   \n",
    "    for element in newlist:\n",
    "        dfhbm1 = df.loc[df['b'] == element, 'l']  #dfhbm1 is dataframe of column l where rows in column b are== to element\n",
    "        dfhbm1['m'] =  dfhbm1.str.cat(sep=', ')\n",
    "        mydict[element] = dfhbm1['m']\n",
    "        \n",
    "    df2 = pd.DataFrame(mydict.items(), columns=['b', \"report\"])  \n",
    "        \n",
    "    df3 = pd.merge(df, df2, on=\"b\")\n",
    "    df3 = df3.drop_duplicates(subset=['report'],keep= 'first')\n",
    "    print df3\n",
    "    \n",
    "    #####################\n",
    "    \n",
    "    df3 = df3.drop_duplicates(subset=['l'],keep= 'first')\n",
    "    df3.to_csv('HemePath2006removeduptestv2.csv', index=False)\n",
    "\n",
    "    df3.to_csv(csvfile, index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
